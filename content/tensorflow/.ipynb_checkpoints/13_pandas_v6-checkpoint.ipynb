{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Introduction to Pandas library?\n",
    "author: Thomas\n",
    "date: '2018-08-29'\n",
    "slug: pandas\n",
    "categories: []\n",
    "tags:\n",
    "  - tf-install\n",
    "header:\n",
    "  caption: ''\n",
    "  image: ''\n",
    "--- \n",
    "\n",
    "# What is Pandas?\n",
    "\n",
    "\n",
    "Pandas is an opensource library that allows to you perform data\n",
    "manipulation in Python. Pandas library is built on top of Numpy, meaning\n",
    "Pandas needs Numpy to operate. Pandas provide an easy way to create,\n",
    "manipulate and wrangle the data. Pandas is also an elegant solution for\n",
    "time series data.\n",
    "\n",
    "## Why use Pandas?\n",
    "\n",
    "\n",
    "Data scientists use Pandas for its following advantages:\n",
    "\n",
    "-   Easily handles missing data\n",
    "\n",
    "-   It uses **Series for one-dimensional data structure** and\n",
    "    **DataFrame for multi-dimensional data structure**\n",
    "\n",
    "-   It provides an efficient way to slice the data\n",
    "\n",
    "-   It provides a flexible way to merge, concatenate or reshape the data\n",
    "\n",
    "-   It includes a powerful time series tool to work with\n",
    "\n",
    "In a nutshell, Pandas is a useful library in data analysis. It can be\n",
    "used to perform data manipulation and analysis. Pandas provide powerful\n",
    "and easy-to-use data structures, as well as the means to quickly perform\n",
    "operations on these structures.\n",
    "\n",
    "## How to install Pandas?\n",
    "\n",
    "\n",
    "To install Pandas library, please refer our tutorial How to install\n",
    "TensorFlow. Pandas is installed by default. In remote case, pandas not\n",
    "installed-\n",
    "\n",
    "You can install Pandas using:\n",
    "\n",
    "-   Anaconda: `conda install -c anaconda pandas`\n",
    "\n",
    "-   In Jupyter Notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a data frame?\n",
    "\n",
    "\n",
    "A data frame is a two-dimensional array, with labeled axes (rows and\n",
    "columns). A data frame is a standard way to store data.\n",
    "\n",
    "Data frame is well-known by statistician and other data practitioners. A\n",
    "data frame is a tabular data, with rows to store the information and\n",
    "columns to name the information. For instance, the price can be the name\n",
    "of a column and 2,3,4 the price values.\n",
    "\n",
    "Below a picture of a Pandas data frame:\n",
    "\n",
    "<img src=\"/tensorflow/13_pandas_v6_files/image001.png\" >\n",
    "\n",
    "\n",
    "## What is a Series?\n",
    "\n",
    "\n",
    "A series is a one-dimensional data structure. It\n",
    "can have any data structure like integer, float, and string. It is\n",
    "useful when you want to perform computation or return a one-dimensional\n",
    "array. A series, by definition, cannot have multiple columns. For the\n",
    "latter case, please use the data frame structure.\n",
    "\n",
    "Series has one parameters:\n",
    "\n",
    "- *Data: can be a list, dictionary or scalar value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     pd.Series([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add the index with `index`. It helps to name the rows. The\n",
    "length should be equal to the size of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1., 2., 3.], index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you create a Pandas series with a missing value for the third rows. Note, missing values in Python are noted \"NaN.\" You can use numpy to create missing value: np.nan artificially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,np.nan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data frame\n",
    "\n",
    "You can convert a numpy array to a pandas data frame with\n",
    "`pd.Data frame()`. The opposite is also possible. To convert a pandas\n",
    "Data Frame to an array, you can use `np.array()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numpy to pandas\n",
    "import numpy as np\n",
    "h = [[1,2],[3,4]] \n",
    "df_h = pd.DataFrame(h)\n",
    "print('Data Frame:', df_h)\n",
    "\n",
    "## Pandas to numpy\n",
    "df_h_n = np.array(df_h)\n",
    "print('Numpy array:', df_h_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a dictionary to create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'Name': [\"John\", \"Smith\"], 'Age': [30, 40]}\n",
    "\n",
    "pd.DataFrame(data=dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range Data\n",
    "\n",
    "Pandas have a convenient API to create a range of date\n",
    "\n",
    "`pd.data_range(``date,period,frequency``)`:\n",
    "\n",
    "-   The first parameter is the starting date\n",
    "\n",
    "-   The second parameter is the number of periods (optional if the end\n",
    "    date is specified)\n",
    "\n",
    "-   The last parameter is the frequency: day: 'D,' month: 'M' and year:\n",
    "    'Y.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create date\n",
    "\n",
    "# Days\n",
    "\n",
    "dates_d = pd.date_range('20300101', periods=6, freq='D')\n",
    "\n",
    "print('Day:', dates_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We month frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months\n",
    "dates_m = pd.date_range('20300101', periods=6, freq='M')\n",
    "print('Month:', dates_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting data\n",
    "\n",
    "You can check the head or tail of the dataset with `head()`, or `tail()`\n",
    "preceded by the name of the panda's data frame\n",
    "\n",
    "Step 1) Create a random sequence with numpy. The sequence has 4 columns\n",
    "and 6 rows\n",
    "\n",
    "random = np.random.randn(6,4)\n",
    "\n",
    "Step 2) Then you create a data frame using pandas.\n",
    "\n",
    "Use `dates_m` as an index for the data frame. It means each row will be\n",
    "given a `name` or an index, corresponding to a date.\n",
    "\n",
    "Finally, you give a name to the 4 columns with the argument columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data with date\n",
    "df = pd.DataFrame(random,\n",
    "                      index=dates_m,\n",
    "                      columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Using head function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Using tail function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) An excellent practice to get a clue about the data is to use\n",
    "`describe()`. It provides the counts, mean, std, min, max and percentile\n",
    "of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice data\n",
    "\n",
    "The last point of this tutorial is about how to slice a pandas data\n",
    "frame.\n",
    "\n",
    "You can use the column name to extract data in a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Slice\n",
    "### Using name\n",
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns, you need to use two times the bracket, [[..,..]]\n",
    "\n",
    "The first pair of bracket means you want to select columns, the second\n",
    "pairs of bracket tells what columns you want to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A', 'B']]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can slice the rows with :\n",
    "\n",
    "The code below returns the first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using a slice for row\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loc function is used to select columns by names. As usual, the\n",
    "values before the coma stand for the rows and after refer to the column.\n",
    "You need to use the brackets to select more than one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi col\n",
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another method to select multiple rows and columns in Pandas.\n",
    "You can use iloc[]. This method uses the index instead of the columns\n",
    "name. The code below returns the same data frame as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop a column\n",
    "\n",
    "You can drop columns using `pd.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['A', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "\n",
    "You can concatenate two DataFrame in Pandas. You can use pd.concat()\n",
    "\n",
    "First of all, you need to create two DataFrames. So far so good, you are\n",
    "already familiar with dataframe creation\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'name': ['John', 'Smith','Paul'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'name': ['Adam', 'Smith' ],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you concatenate the two DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1,df2])\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**   **name**\n",
    "  ------- --------- ----------\n",
    "  **0**   25        John\n",
    "  **1**   30        Smith\n",
    "  **2**   50        Paul\n",
    "  **3**   26        Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Sort values\n",
    "\n",
    "You can sort value with `sort_values`\n",
    "\n",
    "    df_concat.sort_values('Age')\n",
    "    \n",
    "**Output**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Age**   **name**\n",
    "  ------- --------- ----------\n",
    "  **4**   11        Smith\n",
    "  **0**   25        John\n",
    "  **3**   26        Adam\n",
    "  **1**   30        Smith\n",
    "  **2**   50        Paul\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename: change of index\n",
    "\n",
    "You can use `rename` to rename a column in Pandas. The first value is the\n",
    "current column name and the second value is the new column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.rename(columns={\"name\": \"Surname\", \"Age\": \"Age_ppl\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ---------------------------------------- -- --\n",
    "            **Age_ppl**   **Surname**        \n",
    "    ------- -------------- -------------      \n",
    "    **0**   25             John               \n",
    "    **1**   30             Smith              \n",
    "    **2**   50             Paul               \n",
    "    **3**   26             Adam               \n",
    "    **4**   11             Smith              \n",
    "                                              \n",
    "  ---------------------------------------- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV\n",
    "\n",
    "During the TensorFlow tutorial, you will use the adult dataset. It is\n",
    "often used with classification task. It is available in this URL\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "The data is stored in a CSV format. This dataset includes eights\n",
    "categorical variables:\n",
    "\n",
    "This dataset includes eights categorical variables:\n",
    "\n",
    "-   workclass\n",
    "\n",
    "-   education\n",
    "\n",
    "-   marital\n",
    "\n",
    "-   occupation\n",
    "\n",
    "-   relationship\n",
    "\n",
    "-   race\n",
    "\n",
    "-   sex\n",
    "\n",
    "-   native_country\n",
    "\n",
    "moreover, six continuous variables:\n",
    "\n",
    "-   age\n",
    "\n",
    "-   fnlwgt\n",
    "\n",
    "-   education_num\n",
    "\n",
    "-   capital_gain\n",
    "\n",
    "-   capital_loss\n",
    "\n",
    "hours_week\n",
    "\n",
    "To import a CSV dataset, you can use the object pd.read_csv(). The\n",
    "basic argument inside is:\n",
    "\n",
    "-   `filepath_or_buffer`: Path or URL with the data\n",
    "\n",
    "-   `sep=', '`: Define the delimiter to use\n",
    "\n",
    "-   `names=None`: Name the columns. If the dataset has ten columns,\n",
    "    you need to pass ten names\n",
    "\n",
    "-   `index_col=None`: If yes, the first column is used as a row index\n",
    "\n",
    "-   `skipinitialspace=False`: Skip spaces after delimiter.\n",
    "\n",
    "For more information about read*csv(),* please check the official\n",
    "documentation\n",
    "\n",
    "*https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html~~.~~*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Import csv\n",
    "    import pandas as pd\n",
    "    ## Define path data\n",
    "    COLUMNS = ['age','workclass', 'fnlwgt', 'education', 'education_num', 'marital',\n",
    "               'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "               'hours_week', 'native_country', 'label']\n",
    "    PATH = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "    df_train = pd.read_csv(PATH,\n",
    "                           skipinitialspace=True,\n",
    "                           names = COLUMNS,\n",
    "                           index_col=False)\n",
    "\n",
    "    df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(32561, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "\n",
    "An easy way to see the data is to use the `groupby` method. This method\n",
    "can help you to summarize the data by group. Below is a list of methods\n",
    "available with `groupby`:\n",
    "\n",
    "-   count: `count`\n",
    "\n",
    "-   min: `min`\n",
    "\n",
    "-   max: `max`\n",
    "\n",
    "-   mean: `mean`\n",
    "\n",
    "-   median: `median`\n",
    "\n",
    "-   standard deviation: `sdt`\n",
    "\n",
    "-   etc\n",
    "\n",
    "Inside\n",
    "`groupby(), ``you can ``use the column you want to apply the method.`\n",
    "\n",
    "Let's have a look at a single grouping with the adult dataset. You will\n",
    "get the `mean` of all the continuous variables by type of revenue, i.e.,\n",
    "above 50k or below 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(['label']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                 **age**     **fnlwgt**     **education_num**   **capital_gain**   **capital_loss**   **hours_week**\n",
    "  -------------- ----------- -------------- -------------------- ------------------- ------------------- -----------------\n",
    "  **label**                                                                                              \n",
    "  **&lt;=50K**   36.783738   190340.86517   9.595065             148.752468          53.142921           38.840210\n",
    "  **&gt;50K**    44.249841   188005.00000   11.611657            4006.142456         195.001530          45.473026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the minimum of age by type of household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(['label'])['age'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    label\n",
    "    <=50K    17\n",
    "    >50K     19\n",
    "    Name: age, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also group by multiple columns. For instance, you can get the\n",
    "maximum capital gain according to the household type and marital status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(['label', 'marital'])['capital_gain'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    label  marital              \n",
    "    <=50K  Divorced                 34095\n",
    "           Married-AF-spouse         2653\n",
    "           Married-civ-spouse       41310\n",
    "           Married-spouse-absent     6849\n",
    "           Never-married            34095\n",
    "           Separated                 7443\n",
    "           Widowed                   6849\n",
    "    >50K   Divorced                 99999\n",
    "           Married-AF-spouse         7298\n",
    "           Married-civ-spouse       99999\n",
    "           Married-spouse-absent    99999\n",
    "           Never-married            99999\n",
    "           Separated                99999\n",
    "           Widowed                  99999\n",
    "    Name: capital_gain, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a plot following groupby. One way to do it is to use a\n",
    "plot after the grouping.\n",
    "\n",
    "To create a more excellent plot, you will use unstack() after mean() so\n",
    "that you have the same multilevel index, or you join the values by\n",
    "revenue lower than 50k and above 50k. In this case, the plot will have\n",
    "two groups instead of 14 (2*7).\n",
    "\n",
    "If you use Jupyter Notebook, make sure to add % matplotlib inline,\n",
    "otherwise, no plot will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "df_plot = df_train.groupby(['label',\n",
    "'marital'])['capital_gain'].mean().unstack()\n",
    "\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/tensorflow/13_pandas_v6_files/image002.png\" >\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "\n",
    "Below is a summary of the most useful method for data science with\n",
    "Pandas\n",
    "\n",
    "| import data       | read_csv               |\n",
    "|-------------------|------------------------|\n",
    "| create series     | Series                 |\n",
    "| Create Dataframe  | DataFrame              |\n",
    "| Create date range | date_range             |\n",
    "| return head       | head                   |\n",
    "| return tail       | tail                   |\n",
    "| Describe          | describe               |\n",
    "| slice using name  | dataname['columnname'] |\n",
    "| Slice using rows  | data_name[0:5]         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
