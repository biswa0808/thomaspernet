{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Convolutional Neural Network\n",
    "author: Thomas\n",
    "date: '2018-08-29'\n",
    "slug: cnn\n",
    "categories: []\n",
    "tags:\n",
    "  - deep_tf\n",
    "header:\n",
    "    caption: ''\n",
    "    image: ''\n",
    "---\n",
    "\n",
    "<style>\n",
    "body {\n",
    "text-align: justify}\n",
    "</style>\n",
    "\n",
    "# Convolutional neural network\n",
    "\n",
    "Convolutional neural network, also known as *convnets*, is a well-known\n",
    "method in computer vision applications. This type of architecture is\n",
    "dominant to recognize objects from a picture or video.\n",
    "\n",
    "In this tutorial, you will learn how to construct a convnet and how to\n",
    "use TensorFlow to solve the handwritten dataset.\n",
    "\n",
    "## The architecture of a Convolutional Neural Network\n",
    "\n",
    "Think about Facebook a few years ago, after you uploaded a picture to\n",
    "your profile, you were asked to add a name to the face on the picture\n",
    "manually. Nowadays, Facebook uses convnet to tag your friend in the\n",
    "picture automatically.\n",
    "\n",
    "A convolutional neural network is not very difficult to understand. An\n",
    "input image is processed during the convolution phase and later\n",
    "attributed a label.\n",
    "\n",
    "A typical convnet architecture can be summarized in the picture below.\n",
    "First of all, an image is pushed to the network; this is called the\n",
    "input image. Then, the input image goes through an infinite number of\n",
    "steps; this is the convolutional part of the network. Finally, the\n",
    "neural network can predict the digit on the image.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image001.png\" >\n",
    "\n",
    "An image is composed of an array of pixels with height and width. A\n",
    "grayscale image has only one channel while the color image has three\n",
    "channels (each one for Red, Green, and Blue). A channel is stacked over\n",
    "each other. In this tutorial, you will use a grayscale image with only\n",
    "one channel. Each pixel has a value from 0 to 255 to reflect the\n",
    "intensity of the color. For instance, a pixel equals to 0 will show a\n",
    "white color while pixel with a value close to 255 will be darker.\n",
    "\n",
    "Letâ€™s have a look of an image stored in the [MNIST\n",
    "dataset](http://yann.lecun.com/exdb/mnist/). The picture below shows how\n",
    "to represent the picture of the left in a matrix format. Note that, the\n",
    "original matrix has been standardized to be between 0 and 1. For darker\n",
    "color, the value in the matrix is about 0.9 while white pixels have a\n",
    "value of 0.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image002.png\" >\n",
    "\n",
    "## Convolutional operation\n",
    "\n",
    "The most critical component in the model is the convolutional layer.\n",
    "This part aims at reducing the size of the image for faster computations\n",
    "of the weights and improve its generalization.\n",
    "\n",
    "During the convolutional part, the network keeps the essential features\n",
    "of the image and excludes irrelevant noise. For instance, the model is\n",
    "learning how to recognize an elephant from a picture with a mountain in\n",
    "the background. If you use a traditional neural network, the model will\n",
    "assign a weight to all the pixels, including those from the mountain\n",
    "which is not essential and can mislead the network.\n",
    "\n",
    "Instead, a convolutional neural network will use a mathematical\n",
    "technique to extract only the most relevant pixels. This mathematical\n",
    "operation is called convolution. This technique allows the network to\n",
    "learn increasingly complex features at each layer. The convolution\n",
    "divides the matrix into small pieces to learn to most essential elements\n",
    "within each piece.\n",
    "\n",
    "In every convnets, there are four components:\n",
    "\n",
    "1.  Convolution\n",
    "\n",
    "2.  Non Linearity (ReLU)\n",
    "\n",
    "3.  Pooling or Sub Sampling\n",
    "\n",
    "4.  Classification (Fully Connected Layer)\n",
    "\n",
    "-   Convolution\n",
    "\n",
    "The purpose of the convolution is to extract the features of the object\n",
    "on the image locally. It means the network will learn specific patterns\n",
    "within the picture and will be able to recognize it everywhere in the\n",
    "picture.\n",
    "\n",
    "Convolution is an element-wise multiplication. The concept is easy to\n",
    "understand. The computer will scan a part of the image, usually with a\n",
    "dimension of 3x3 and multiplies it to a filter. The output of the\n",
    "element-wise multiplication is called a feature map. This step is\n",
    "repeated until all the image is scanned. Note that, after the\n",
    "convolution, the size of the image is reduced.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image003.png\" >\n",
    "\n",
    "Below, there is a URL to see in action how convolution works.\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/fV8esV6419OdEltpbO/giphy.gif\" width=\"400\" height=\"400\" />\n",
    "\n",
    "There are numerous channels available. Below, we listed some of the\n",
    "channels. You can see that each filter has a specific purpose. Note, in\n",
    "the picture below; the Kernel is a synonym of the filter.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image005.png\" >\n",
    "[Source](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "\n",
    "*Arithmetic behind the convolution*\n",
    "\n",
    "The convolutional phase will apply the filter on a small array of pixels\n",
    "within the picture. The filter will move along the input image with a\n",
    "general shape of 3x3 or 5x5. It means the network will slide these\n",
    "windows across all the input image and compute the convolution. The\n",
    "image below shows how the convolution operates. The size of the patch is\n",
    "3x3, and the output matrix is the result of the element-wise operation\n",
    "between the image matrix and the filter.\n",
    "\n",
    "<img src=\"http://machinelearninguru.com/_images/topics/computer_vision/basics/convolutional_layer_1/stride1.gif\" width=\"400\" height=\"400\" />\n",
    "\n",
    "[Source](http://machinelearninguru.com/computer_vision/basics/convolution/convolution_layer.html)\n",
    "\n",
    "You notice that the width and height of the output can be different from\n",
    "the width and height of the input. It happens because of the border\n",
    "effect.\n",
    "\n",
    "**Border effect**\n",
    "\n",
    "Image has a 5x5 features map and a 3x3 filter. There is only one window\n",
    "in the center where the filter can screen an 3x3 grid. The output\n",
    "feature map will shrink by two tiles alongside with a 3x3 dimension.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image007.png\" >\n",
    "\n",
    "To get the same output dimension as the input dimension, you need to add\n",
    "padding. Padding consists of adding the right number of rows and columns\n",
    "on each side of the matrix. It will allow the convolution to center fit\n",
    "every input tile. In the image below, the input/output matrix have the\n",
    "same dimension 5x5\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image008.png\" >\n",
    "\n",
    "When you define the network, the convolved features are controlled by\n",
    "three parameters:\n",
    "\n",
    "1.  Depth: It defines the number of filters to apply during the\n",
    "    convolution. In the previous example, you saw a depth of 1, meaning\n",
    "    only one filter is used. In most of the case, there is more than one\n",
    "    filter. The picture below shows the operations done in a situation\n",
    "    with three filters\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image009.gif\" width=\"400\" height=\"400\" />\n",
    "\n",
    "1.  Stride: It defines the number of \"pixel's jump\" between two slices.\n",
    "    If the stride is equal to 1, the windows will move with a pixel's\n",
    "    spread of one. If the stride is equal to two, the windows will jump\n",
    "    by 2 pixels. If you increase the stride, you will have smaller\n",
    "    feature maps.\n",
    "\n",
    "Example stride 1\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image010.png\" >\n",
    "\n",
    "Image stride 2\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image011.png\" >\n",
    "\n",
    "1.  Zero-padding: A padding is an operation of adding a corresponding\n",
    "    number of rows and column on each side of the input features maps.\n",
    "    In this case, the output has the same dimension as the input.\n",
    "\n",
    "-   Non Linearity (ReLU)\n",
    "\n",
    "At the end of the convolution operation, the output is subject to an\n",
    "activation function to allow non-linearity. The usual activation\n",
    "function for convnet is the Relu. All the pixel with a negative value\n",
    "will be replaced by zero.\n",
    "\n",
    "-   Max-pooling operation\n",
    "\n",
    "This step is easy to understand. The purpose of the pooling is to reduce\n",
    "the dimensionality of the input image. The steps are done to reduce the\n",
    "computational complexity of the operation. By diminishing the\n",
    "dimensionality, the network has lower weights to compute, so it prevents\n",
    "overfitting.\n",
    "\n",
    "In this stage, you need to define the size and the stride. A standard\n",
    "way to pool the input image is to use the maximum value of the feature\n",
    "map. Look at the picture below. The \"pooling\" will screen a four\n",
    "submatrix of the 4x4 feature map and return the maximum value. The\n",
    "pooling takes the maximum value of a 2x2 array and then move this\n",
    "windows by two pixels. For instance, the first sub-matrix is\n",
    "\\[3,1,3,2\\], the pooling will return the maximum, which is 3.\n",
    "\n",
    "<img src=\"/tensorflow/20_CNN_v7_files/image012.png\" >\n",
    "\n",
    "There is another pooling operation such as the mean.\n",
    "\n",
    "This operation aggressively reduces the size of the feature map\n",
    "\n",
    "-   Fully connected layers\n",
    "\n",
    "The last step consists of building a traditional artificial neural\n",
    "network as you did in the previous tutorial. You connect all neurons\n",
    "from the previous layer to the next layer. You use a softmax activation\n",
    "function to classify the number on the input image.\n",
    "\n",
    "**Recap:** \n",
    "\n",
    "Convolutional Neural network compiles different layers before making a\n",
    "prediction. A neural network has:\n",
    "\n",
    "-   A convolutional layer\n",
    "\n",
    "-   Relu Activation function\n",
    "\n",
    "-   Pooling layer\n",
    "\n",
    "-   Densely connected layer\n",
    "\n",
    "The convolutional layers apply different filters on a subregion of the\n",
    "picture. The Relu activation function adds non-linearity, and the\n",
    "pooling layers reduce the dimensionality of the features maps.\n",
    "\n",
    "All these layers extract essential information from the images. At last,\n",
    "the features map are feed to a primary fully connected layer with a\n",
    "softmax function to make a prediction.\n",
    "\n",
    "# Train CNN with TensorFlow\n",
    "\n",
    "Now that you are familiar with the building block of a convnets, you are\n",
    "ready to build one with TensorFlow. We will use the MNIST dataset.\n",
    "\n",
    "The data preparation is the same as the previous tutorial. You can run\n",
    "the codes and jump directly to the architecture of the CNN.\n",
    "\n",
    "You will follow the steps below:\n",
    "\n",
    "Step 1: Upload Dataset\n",
    "\n",
    "Step 2: Input layer\n",
    "\n",
    "Step 3: Convolutional layer\n",
    "\n",
    "Step 4: Pooling layer\n",
    "\n",
    "Step 5: Second Convolutional Layer and Pooling Layer\n",
    "\n",
    "Step 6: Dense layer\n",
    "\n",
    "Step 7: Logit Layer\n",
    "\n",
    "**Step 1: Upload Dataset**\n",
    "\n",
    "The MNIST dataset is available at this\n",
    "[URL](https://www.dropbox.com/sh/jm9jo0d58oggeb9/AAAZrRHvHFGYdCHssXpEH2o1a?dl=0).\n",
    "\n",
    "Please download it and store it in Downloads. You can upload it with\n",
    "`fetch_mldata('MNIST original').\n",
    "\n",
    "**Create a train/test set**\n",
    "\n",
    "You need to split the dataset with `train_test_split\n",
    "\n",
    "**Scale the features**\n",
    "\n",
    "Finally, you can scale the feature with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a Windows user, run the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change USERNAME by the username of your machine\n",
    "\n",
    "## Windows USER\n",
    "\n",
    "mnist = fetch_mldata('C:\\\\Users\\\\USERNAME\\\\Downloads\\\\MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, you need to run this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mac User\n",
    "\n",
    "mnist = fetch_mldata('/Users/USERNAME/Downloads/MNIST original')\n",
    "\n",
    "\n",
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data,\n",
    "                                                    mnist.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "y_train  = y_train.astype(int)\n",
    "y_test  = y_test.astype(int)\n",
    "batch_size =len(X_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resclae\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Train\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "# test\n",
    "X_test_scaled = scaler.fit_transform(X_test.astype(np.float64))\n",
    "\n",
    "feature_columns = [\n",
    "      tf.feature_column.numeric_column('x', shape=X_train_scaled.shape[1:])]\n",
    "\n",
    "X_train_scaled.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN\n",
    "\n",
    "A CNN uses filters on the raw pixel of an image to learn details pattern\n",
    "compare to global pattern with a traditional neural net. To construct a\n",
    "CNN, you need to define:\n",
    "\n",
    "1.  A convolutional layer: Apply `n` number of filters to the feature\n",
    "    map. After the convolution, you need to use a Relu activation\n",
    "    function to add non-linearity to the network.\n",
    "\n",
    "2.  Pooling layer: The next step after the convolution is to downsample\n",
    "    the feature max. The purpose is to reduce the dimensionality of the\n",
    "    feature map to prevent overfitting and improve the computation\n",
    "    speed. Max pooling is the conventional technique, which divides the\n",
    "    feature maps into subregions (usually with a 2x2 size) and keeps\n",
    "    only the maximum values.\n",
    "\n",
    "3.  Fully connected layers: All neurons from the previous layers are\n",
    "    connected to the next layers. The CNN will classify the label\n",
    "    according to the features from the convolutional layers and reduced\n",
    "    with the pooling layer.\n",
    "\n",
    "**CNN architecture**\n",
    "\n",
    "-   Convolutional Layer: Applies 14 5x5 filters (extracting 5x5-pixel\n",
    "    subregions), with ReLU activation function\n",
    "\n",
    "-   Pooling Layer: Performs max pooling with a 2x2 filter and stride of\n",
    "    2 (which specifies that pooled regions do not overlap)\n",
    "\n",
    "-   Convolutional Layer: Applies 36 5x5 filters, with ReLU activation\n",
    "    function\n",
    "\n",
    "-   Pooling Layer \\#2: Again, performs max pooling with a 2x2 filter and\n",
    "    stride of 2\n",
    "\n",
    "-   1,764 neurons, with dropout regularization rate of 0.4 (probability\n",
    "    of 0.4 that any given element will be dropped during training)\n",
    "\n",
    "-   Dense Layer (Logits Layer): 10 neurons, one for each digit target\n",
    "    class (0â€“9).\n",
    "\n",
    "There are three important modules to use to create a CNN:\n",
    "\n",
    "-   conv2d(). Constructs a two-dimensional convolutional layer with the\n",
    "    number of filters, filter kernel size, padding, and activation\n",
    "    function as arguments.\n",
    "\n",
    "-   max\\_pooling2d(). Constructs a two-dimensional pooling layer using\n",
    "    the max-pooling algorithm.\n",
    "\n",
    "-   dense(). Constructs a dense layer with the hidden layers and units\n",
    "\n",
    "You will define a function to build the CNN. Let's see in detail how to\n",
    "construct each building block before to wrap everything together in the\n",
    "function.\n",
    "\n",
    "**Step 2: Input layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(tensor = features[\"x\"],shape =[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to define a tensor with the shape of the data. For that, you\n",
    "can use the module `tf.reshape`. In this module, you need to declare the\n",
    "tensor to reshape and the shape of the tensor. The first argument is the\n",
    "features of the data, which is defined in the argument of the function.\n",
    "\n",
    "A picture has a height, a width, and a channel. The MNIST dataset is a\n",
    "monochronic picture with a 28x28 size. We set the batch size to -1 in\n",
    "the shape argument so that it takes the shape of the `features[\"x\"]`.\n",
    "The advantage is to make the batch size hyperparameters to tune. If the\n",
    "batch size is set to 7, then the tensor will feed 5,488 values\n",
    "(28\\**28\\**7).\n",
    "\n",
    "**Step 3: Convolutional layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first Convolutional Layer\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=14,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first convolutional layer has 14 filters with a kernel size of 5x5\n",
    "with the same padding. The same padding means both the output tensor and\n",
    "input tensor should have the same height and width. Tensorflow will add\n",
    "zeros to the rows and columns to ensure the same size.\n",
    "\n",
    "You use the Relu activation function. The output size will be\n",
    "`[28, 28, 14]`.\n",
    "\n",
    "**Step 4: Pooling layer**\n",
    "\n",
    "The next step after the convolution is the pooling computation. The\n",
    "pooling computation will reduce the dimensionality of the data. You can\n",
    "use the module `max_pooling2d` with a size of 2x2 and stride of 2. You\n",
    "use the previous layer as input. The output size will be\n",
    "`[batch_size, 14, 14, 14]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first Pooling Layer \n",
    "\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Second Convolutional Layer and Pooling Layer**\n",
    "\n",
    "The second convolutional layer has 32 filters, with an output size of\n",
    "`[batch_size, 14, 14, 32]`. The pooling layer has the same size as\n",
    "before and the output shape is `[batch_size, 14, 14, 18]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=36,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Dense layer**\n",
    "\n",
    "Then, you need to define the fully-connected layer. The feature map has\n",
    "to be flatten before to be connected with the dense layer. You can use\n",
    "the module `reshape` with a size of 7\\**7\\**36.\n",
    "\n",
    "The dense layer will connect 1764 neurons. You add a Relu activation\n",
    "function. Besides, you add a dropout regularization term with a rate of\n",
    "0.3, meaning 30 percents of the weights will be set to 0. Note that, the\n",
    "dropout takes place only during the training phase. The function\n",
    "`cnn_model_fn` has an argument `mode` to declare if the model needs to\n",
    "be trained or to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 36])\n",
    "\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=7 * 7 * 36, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.3, training=mode == tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Logit Layer**\n",
    "\n",
    "Finally, you can define the last layer with the prediction of the model.\n",
    "The output shape is equal to the batch size and 10, the total number of\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a dictionary containing the classes and the probability\n",
    "of each class. The module `tf.argmax``()` with returns the highest value\n",
    "if the logit layers. The softmax function returns the probability of\n",
    "each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "      # Generate predictions\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only want to return the dictionnary `prediction` when mode is set to\n",
    "`prediction`. You add this codes to dispay the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consists to compute the loss of the model. In the last\n",
    "tutorial, you learnt that the loss function for a multiclass model is\n",
    "cross entropy. The loss is easily computed with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to optimize the model, that is to find the best values\n",
    "of the weights. For that, you use a Gradient descent optimizer with a\n",
    "learning rate of 0.001. The objective is to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are done with the CNN. However, you want to display the performance\n",
    "metrics during the evaluation mode. The performance metrics for a\n",
    "multiclass model is the `accuracy` metrics. Tensorflow is equipped with\n",
    "a module `accuracy` with two arguments, the labels, and the predicted\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You created your first CNN and you are ready to wrap\n",
    "everything into a function in order to use it to train and evaluate the\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=36,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 36])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=7 * 7 * 36, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics Evaluation mode\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps below are the same as the previous tutorials.\n",
    "\n",
    "First of all, you define an estimator with the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"train/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN takes many times to train, therefore, you create a Logging hook to\n",
    "store the values of the softmax layers every 50 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to estimate the model. You set a batch size of 100 and\n",
    "shuffle the data. Note that we set training steps of 16.000, it can take\n",
    "lots of time to train. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train_scaled},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=16000,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is train, you can evaluate it and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test_scaled},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the current architecture, you get an accuracy of 97%. You can change the architecture, the batch size and the number of iteration to improve the accuracy. The CNN neural network has performed far better than ANN or logistic regression. In the tutorial on an artificial neural network, you had an accuracy of 96%, which is lower the CNN. The performances of the CNN are impressive with a larger image, both in term of speed computation and accuracy.\n",
    "\n",
    "## Summary\n",
    "\n",
    "A convolutional neural network works very well to evaluate picture. This\n",
    "type of architecture is dominant to recognize objects from a picture or\n",
    "video.\n",
    "\n",
    "To build a CNN, you need to follow six steps:\n",
    "\n",
    "Step 1: Input layer:\n",
    "\n",
    "This step reshapes the data. The shape is equal to the square root of\n",
    "the number of pixels. For instance, if a picture has 156 pixels, then\n",
    "the shape is 26x26. You need to specify if the picture has colour or\n",
    "not. If yes, then you had 3 to the shape- 3 for RGB-, otherwise 1.\n",
    "\n",
    "input\\_layer = tf.reshape(tensor = features\\[\"x\"\\],shape =\\[-1, 28, 28,\n",
    "1\\])\n",
    "\n",
    "Step 2: Convolutional layer\n",
    "\n",
    "Next, you need to create the convolutional layers. You apply different\n",
    "filters to allow the network to learn important feature. You specify the\n",
    "size of the kernel and the amount of filters.\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "inputs=input\\_layer,\n",
    "filters=14,\n",
    "kernel\\_size=\\[5, 5\\],\n",
    "padding=\"same\",\n",
    "activation=tf.nn.relu)\n",
    "\n",
    "Step 3: Pooling layer\n",
    "\n",
    "In the third step, you add a pooling layer. This layer decreases the\n",
    "size of the input. It does so by taking the maximum value of the a\n",
    "sub-matrix. For instance, if the sub-matrix is \\[3,1,3,2\\], the pooling\n",
    "will return the maximum, which is 3.\n",
    "\n",
    "pool1 = tf.layers.max\\_pooling2d(inputs=conv1, pool\\_size=\\[2, 2\\],\n",
    "strides=2)\n",
    "\n",
    "Step 4: Add Convolutional Layer and Pooling Layer\n",
    "\n",
    "In this step, you can add as much as you want conv layers and pooling\n",
    "layers. Google uses architecture with more than 20 conv layers.\n",
    "\n",
    "Step 5: Dense layer\n",
    "\n",
    "The step 5 flatten the previous to create a fully connected layers. In\n",
    "this step, you can use different activation function and add a dropout\n",
    "effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 36])\n",
    "\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=7 * 7 * 36, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.3, training=mode == tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Logit Layer\n",
    "\n",
    "The final step is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(inputs=dropout, units=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
